{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import mxnet as mx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = mx.test_utils.get_mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "train_iter = mx.io.NDArrayIter(mnist['train_data'],mnist['train_label'],batch_size,shuffle=True)\n",
    "val_iter = mx.io.NDArrayIter(mnist['test_data'],mnist['test_label'],batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approach 1 : Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = mx.sym.var('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the data from 4-D shape into 2-D (batch_size, num_channel*width*height)\n",
    "data = mx.sym.flatten(data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first fully-connected layer and the corresponding activation function\n",
    "fc1 = mx.sym.FullyConnected(data=data,num_hidden=128)\n",
    "act1 = mx.sym.Activation(data=fc1,act_type=\"relu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The second fully-connected Layer and the corresponding activation function\n",
    "fc2 = mx.sym.FullyConnected(data=act1,num_hidden=64)\n",
    "act2 = mx.sym.Activation(data=fc2,act_type=\"relu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST has 10 classes\n",
    "fc3 = mx.sym.FullyConnected(data=act2,num_hidden=10)\n",
    "# Softmax with cross entropy Loss\n",
    "mlp = mx.sym.SoftmaxOutput(data=fc3,name='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper-parameters   mini_batch_size = 100    learning_rate = 0.1  epoch = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch[0] Batch [100]\tSpeed: 42129.17 samples/sec\taccuracy=0.109307\n",
      "INFO:root:Epoch[0] Batch [200]\tSpeed: 43909.39 samples/sec\taccuracy=0.114900\n",
      "INFO:root:Epoch[0] Batch [300]\tSpeed: 44366.24 samples/sec\taccuracy=0.110800\n",
      "INFO:root:Epoch[0] Batch [400]\tSpeed: 44366.61 samples/sec\taccuracy=0.114400\n",
      "INFO:root:Epoch[0] Batch [500]\tSpeed: 31728.78 samples/sec\taccuracy=0.118300\n",
      "INFO:root:Epoch[0] Train-accuracy=0.228081\n",
      "INFO:root:Epoch[0] Time cost=1.488\n",
      "INFO:root:Epoch[0] Validation-accuracy=0.383200\n",
      "INFO:root:Epoch[1] Batch [100]\tSpeed: 30611.69 samples/sec\taccuracy=0.475842\n",
      "INFO:root:Epoch[1] Batch [200]\tSpeed: 37980.15 samples/sec\taccuracy=0.672400\n",
      "INFO:root:Epoch[1] Batch [300]\tSpeed: 51684.35 samples/sec\taccuracy=0.777200\n",
      "INFO:root:Epoch[1] Batch [400]\tSpeed: 52215.30 samples/sec\taccuracy=0.803800\n",
      "INFO:root:Epoch[1] Batch [500]\tSpeed: 51275.49 samples/sec\taccuracy=0.823000\n",
      "INFO:root:Epoch[1] Train-accuracy=0.837677\n",
      "INFO:root:Epoch[1] Time cost=1.471\n",
      "INFO:root:Epoch[1] Validation-accuracy=0.853300\n",
      "INFO:root:Epoch[2] Batch [100]\tSpeed: 52772.48 samples/sec\taccuracy=0.860396\n",
      "INFO:root:Epoch[2] Batch [200]\tSpeed: 53198.38 samples/sec\taccuracy=0.870000\n",
      "INFO:root:Epoch[2] Batch [300]\tSpeed: 53906.86 samples/sec\taccuracy=0.886600\n",
      "INFO:root:Epoch[2] Batch [400]\tSpeed: 47731.59 samples/sec\taccuracy=0.891000\n",
      "INFO:root:Epoch[2] Batch [500]\tSpeed: 47974.71 samples/sec\taccuracy=0.905600\n",
      "INFO:root:Epoch[2] Train-accuracy=0.914646\n",
      "INFO:root:Epoch[2] Time cost=1.189\n",
      "INFO:root:Epoch[2] Validation-accuracy=0.916900\n",
      "INFO:root:Epoch[3] Batch [100]\tSpeed: 49638.03 samples/sec\taccuracy=0.920297\n",
      "INFO:root:Epoch[3] Batch [200]\tSpeed: 51276.55 samples/sec\taccuracy=0.920200\n",
      "INFO:root:Epoch[3] Batch [300]\tSpeed: 45927.38 samples/sec\taccuracy=0.928300\n",
      "INFO:root:Epoch[3] Batch [400]\tSpeed: 50508.95 samples/sec\taccuracy=0.928900\n",
      "INFO:root:Epoch[3] Batch [500]\tSpeed: 51952.14 samples/sec\taccuracy=0.937900\n",
      "INFO:root:Epoch[3] Train-accuracy=0.942424\n",
      "INFO:root:Epoch[3] Time cost=1.211\n",
      "INFO:root:Epoch[3] Validation-accuracy=0.941700\n",
      "INFO:root:Epoch[4] Batch [100]\tSpeed: 53906.79 samples/sec\taccuracy=0.942673\n",
      "INFO:root:Epoch[4] Batch [200]\tSpeed: 48667.70 samples/sec\taccuracy=0.943500\n",
      "INFO:root:Epoch[4] Batch [300]\tSpeed: 48910.94 samples/sec\taccuracy=0.947300\n",
      "INFO:root:Epoch[4] Batch [400]\tSpeed: 51157.04 samples/sec\taccuracy=0.948600\n",
      "INFO:root:Epoch[4] Batch [500]\tSpeed: 50505.85 samples/sec\taccuracy=0.952400\n",
      "INFO:root:Epoch[4] Train-accuracy=0.955657\n",
      "INFO:root:Epoch[4] Time cost=1.188\n",
      "INFO:root:Epoch[4] Validation-accuracy=0.951000\n",
      "INFO:root:Epoch[5] Batch [100]\tSpeed: 31431.71 samples/sec\taccuracy=0.957921\n",
      "INFO:root:Epoch[5] Batch [200]\tSpeed: 39474.43 samples/sec\taccuracy=0.954100\n",
      "INFO:root:Epoch[5] Batch [300]\tSpeed: 32896.81 samples/sec\taccuracy=0.958200\n",
      "INFO:root:Epoch[5] Batch [400]\tSpeed: 47073.85 samples/sec\taccuracy=0.957200\n",
      "INFO:root:Epoch[5] Batch [500]\tSpeed: 46206.52 samples/sec\taccuracy=0.960600\n",
      "INFO:root:Epoch[5] Train-accuracy=0.963232\n",
      "INFO:root:Epoch[5] Time cost=1.586\n",
      "INFO:root:Epoch[5] Validation-accuracy=0.957300\n",
      "INFO:root:Epoch[6] Batch [100]\tSpeed: 48442.36 samples/sec\taccuracy=0.964752\n",
      "INFO:root:Epoch[6] Batch [200]\tSpeed: 51284.45 samples/sec\taccuracy=0.960900\n",
      "INFO:root:Epoch[6] Batch [300]\tSpeed: 41774.65 samples/sec\taccuracy=0.966000\n",
      "INFO:root:Epoch[6] Batch [400]\tSpeed: 46206.36 samples/sec\taccuracy=0.961000\n",
      "INFO:root:Epoch[6] Batch [500]\tSpeed: 53333.74 samples/sec\taccuracy=0.965300\n",
      "INFO:root:Epoch[6] Train-accuracy=0.968081\n",
      "INFO:root:Epoch[6] Time cost=1.259\n",
      "INFO:root:Epoch[6] Validation-accuracy=0.961200\n",
      "INFO:root:Epoch[7] Batch [100]\tSpeed: 53618.32 samples/sec\taccuracy=0.970297\n",
      "INFO:root:Epoch[7] Batch [200]\tSpeed: 53904.78 samples/sec\taccuracy=0.967800\n",
      "INFO:root:Epoch[7] Batch [300]\tSpeed: 53189.88 samples/sec\taccuracy=0.971000\n",
      "INFO:root:Epoch[7] Batch [400]\tSpeed: 53333.47 samples/sec\taccuracy=0.965600\n",
      "INFO:root:Epoch[7] Batch [500]\tSpeed: 53618.67 samples/sec\taccuracy=0.969700\n",
      "INFO:root:Epoch[7] Train-accuracy=0.971717\n",
      "INFO:root:Epoch[7] Time cost=1.138\n",
      "INFO:root:Epoch[7] Validation-accuracy=0.964700\n",
      "INFO:root:Epoch[8] Batch [100]\tSpeed: 52356.09 samples/sec\taccuracy=0.974950\n",
      "INFO:root:Epoch[8] Batch [200]\tSpeed: 52741.23 samples/sec\taccuracy=0.971200\n",
      "INFO:root:Epoch[8] Batch [300]\tSpeed: 55546.34 samples/sec\taccuracy=0.974500\n",
      "INFO:root:Epoch[8] Batch [400]\tSpeed: 51812.75 samples/sec\taccuracy=0.970900\n",
      "INFO:root:Epoch[8] Batch [500]\tSpeed: 52224.08 samples/sec\taccuracy=0.974400\n",
      "INFO:root:Epoch[8] Train-accuracy=0.976465\n",
      "INFO:root:Epoch[8] Time cost=1.213\n",
      "INFO:root:Epoch[8] Validation-accuracy=0.967100\n",
      "INFO:root:Epoch[9] Batch [100]\tSpeed: 47074.07 samples/sec\taccuracy=0.977327\n",
      "INFO:root:Epoch[9] Batch [200]\tSpeed: 52772.28 samples/sec\taccuracy=0.974700\n",
      "INFO:root:Epoch[9] Batch [300]\tSpeed: 46964.75 samples/sec\taccuracy=0.977300\n",
      "INFO:root:Epoch[9] Batch [400]\tSpeed: 36329.07 samples/sec\taccuracy=0.974500\n",
      "INFO:root:Epoch[9] Batch [500]\tSpeed: 44366.24 samples/sec\taccuracy=0.977300\n",
      "INFO:root:Epoch[9] Train-accuracy=0.980000\n",
      "INFO:root:Epoch[9] Time cost=1.319\n",
      "INFO:root:Epoch[9] Validation-accuracy=0.969200\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logging.getLogger().setLevel(logging.DEBUG) #Logging to stdout\n",
    "# create a trainable module on CPU\n",
    "mlp_model = mx.mod.Module(symbol=mlp,context=mx.cpu())\n",
    "mlp_model.fit(train_iter,#train data\n",
    "             eval_data=val_iter, # validation data\n",
    "             optimizer='sgd',  #use Stochastic Gradient Descent to train\n",
    "             optimizer_params={'learning_rate':0.1}, #use fixed learning rate\n",
    "             eval_metric='acc',   # report accuracy during training\n",
    "             batch_end_callback = mx.callback.Speedometer(batch_size,100), #output progress for each 100 data batches\n",
    "             num_epoch=10)  # train for at most 10 dataset passes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction\n",
    "test_iter = mx.io.NDArrayIter(mnist['test_data'],None,batch_size)\n",
    "prob = mlp_model.predict(test_iter)\n",
    "assert prob.shape == (10000,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EvalMetric: {'accuracy': 0.9692}\n"
     ]
    }
   ],
   "source": [
    "test_iter = mx.io.NDArrayIter(mnist['test_data'],mnist['test_label'],batch_size)\n",
    "# predict accuracy of mlp\n",
    "acc = mx.metric.Accuracy()\n",
    "mlp_model.score(test_iter,acc)\n",
    "print(acc)\n",
    "assert acc.get()[1]>0.96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approach 2: Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = mx.sym.var('data')\n",
    "# first conv layer\n",
    "conv1 = mx.sym.Convolution(data=data, kernel=(5,5), num_filter=20)\n",
    "tanh1 = mx.sym.Activation(data=conv1, act_type=\"tanh\")\n",
    "pool1 = mx.sym.Pooling(data=tanh1, pool_type=\"max\", kernel=(2,2), stride=(2,2))\n",
    "# second conv layer\n",
    "conv2 = mx.sym.Convolution(data=pool1, kernel=(5,5), num_filter=50)\n",
    "tanh2 = mx.sym.Activation(data=conv2, act_type=\"tanh\")\n",
    "pool2 = mx.sym.Pooling(data=tanh2, pool_type=\"max\", kernel=(2,2), stride=(2,2))\n",
    "# first fullc layer\n",
    "flatten = mx.sym.flatten(data=pool2)\n",
    "fc1 = mx.symbol.FullyConnected(data=flatten, num_hidden=500)\n",
    "tanh3 = mx.sym.Activation(data=fc1, act_type=\"tanh\")\n",
    "# second fullc\n",
    "fc2 = mx.sym.FullyConnected(data=tanh3, num_hidden=10)\n",
    "# softmax loss\n",
    "lenet = mx.sym.SoftmaxOutput(data=fc2, name='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch[0] Batch [100]\tSpeed: 1002.50 samples/sec\taccuracy=0.109802\n",
      "INFO:root:Epoch[0] Batch [200]\tSpeed: 990.84 samples/sec\taccuracy=0.114900\n",
      "INFO:root:Epoch[0] Batch [300]\tSpeed: 995.11 samples/sec\taccuracy=0.110800\n",
      "INFO:root:Epoch[0] Batch [400]\tSpeed: 1008.46 samples/sec\taccuracy=0.112200\n",
      "INFO:root:Epoch[0] Batch [500]\tSpeed: 834.36 samples/sec\taccuracy=0.115800\n",
      "INFO:root:Epoch[0] Train-accuracy=0.109596\n",
      "INFO:root:Epoch[0] Time cost=63.798\n",
      "INFO:root:Epoch[0] Validation-accuracy=0.113500\n",
      "INFO:root:Epoch[1] Batch [100]\tSpeed: 858.50 samples/sec\taccuracy=0.116139\n",
      "INFO:root:Epoch[1] Batch [200]\tSpeed: 981.73 samples/sec\taccuracy=0.506300\n",
      "INFO:root:Epoch[1] Batch [300]\tSpeed: 813.07 samples/sec\taccuracy=0.850800\n",
      "INFO:root:Epoch[1] Batch [400]\tSpeed: 836.76 samples/sec\taccuracy=0.893200\n",
      "INFO:root:Epoch[1] Batch [500]\tSpeed: 888.06 samples/sec\taccuracy=0.921000\n",
      "INFO:root:Epoch[1] Train-accuracy=0.937677\n",
      "INFO:root:Epoch[1] Time cost=67.488\n",
      "INFO:root:Epoch[1] Validation-accuracy=0.942700\n",
      "INFO:root:Epoch[2] Batch [100]\tSpeed: 955.58 samples/sec\taccuracy=0.947228\n",
      "INFO:root:Epoch[2] Batch [200]\tSpeed: 970.66 samples/sec\taccuracy=0.949700\n",
      "INFO:root:Epoch[2] Batch [300]\tSpeed: 990.87 samples/sec\taccuracy=0.955700\n",
      "INFO:root:Epoch[2] Batch [400]\tSpeed: 988.87 samples/sec\taccuracy=0.959900\n",
      "INFO:root:Epoch[2] Batch [500]\tSpeed: 1004.95 samples/sec\taccuracy=0.967100\n",
      "INFO:root:Epoch[2] Train-accuracy=0.967677\n",
      "INFO:root:Epoch[2] Time cost=60.815\n",
      "INFO:root:Epoch[2] Validation-accuracy=0.971300\n",
      "INFO:root:Epoch[3] Batch [100]\tSpeed: 1014.90 samples/sec\taccuracy=0.972376\n",
      "INFO:root:Epoch[3] Batch [200]\tSpeed: 1008.08 samples/sec\taccuracy=0.971300\n",
      "INFO:root:Epoch[3] Batch [300]\tSpeed: 1011.34 samples/sec\taccuracy=0.974000\n",
      "INFO:root:Epoch[3] Batch [400]\tSpeed: 981.45 samples/sec\taccuracy=0.975200\n",
      "INFO:root:Epoch[3] Batch [500]\tSpeed: 1009.51 samples/sec\taccuracy=0.976700\n",
      "INFO:root:Epoch[3] Train-accuracy=0.977778\n",
      "INFO:root:Epoch[3] Time cost=59.621\n",
      "INFO:root:Epoch[3] Validation-accuracy=0.980600\n",
      "INFO:root:Epoch[4] Batch [100]\tSpeed: 994.40 samples/sec\taccuracy=0.980297\n",
      "INFO:root:Epoch[4] Batch [200]\tSpeed: 1006.99 samples/sec\taccuracy=0.978300\n",
      "INFO:root:Epoch[4] Batch [300]\tSpeed: 1013.97 samples/sec\taccuracy=0.980600\n",
      "INFO:root:Epoch[4] Batch [400]\tSpeed: 1010.02 samples/sec\taccuracy=0.981600\n",
      "INFO:root:Epoch[4] Batch [500]\tSpeed: 1005.59 samples/sec\taccuracy=0.982500\n",
      "INFO:root:Epoch[4] Train-accuracy=0.983838\n",
      "INFO:root:Epoch[4] Time cost=59.575\n",
      "INFO:root:Epoch[4] Validation-accuracy=0.983800\n",
      "INFO:root:Epoch[5] Batch [100]\tSpeed: 990.01 samples/sec\taccuracy=0.984554\n",
      "INFO:root:Epoch[5] Batch [200]\tSpeed: 992.87 samples/sec\taccuracy=0.982300\n",
      "INFO:root:Epoch[5] Batch [300]\tSpeed: 995.82 samples/sec\taccuracy=0.985600\n",
      "INFO:root:Epoch[5] Batch [400]\tSpeed: 1001.67 samples/sec\taccuracy=0.984500\n",
      "INFO:root:Epoch[5] Batch [500]\tSpeed: 1007.97 samples/sec\taccuracy=0.984600\n",
      "INFO:root:Epoch[5] Train-accuracy=0.986768\n",
      "INFO:root:Epoch[5] Time cost=60.124\n",
      "INFO:root:Epoch[5] Validation-accuracy=0.985500\n",
      "INFO:root:Epoch[6] Batch [100]\tSpeed: 916.61 samples/sec\taccuracy=0.987426\n",
      "INFO:root:Epoch[6] Batch [200]\tSpeed: 964.15 samples/sec\taccuracy=0.985700\n",
      "INFO:root:Epoch[6] Batch [300]\tSpeed: 976.17 samples/sec\taccuracy=0.988300\n",
      "INFO:root:Epoch[6] Batch [400]\tSpeed: 990.55 samples/sec\taccuracy=0.986200\n",
      "INFO:root:Epoch[6] Batch [500]\tSpeed: 992.62 samples/sec\taccuracy=0.987000\n",
      "INFO:root:Epoch[6] Train-accuracy=0.988384\n",
      "INFO:root:Epoch[6] Time cost=61.886\n",
      "INFO:root:Epoch[6] Validation-accuracy=0.986500\n",
      "INFO:root:Epoch[7] Batch [100]\tSpeed: 979.51 samples/sec\taccuracy=0.988713\n",
      "INFO:root:Epoch[7] Batch [200]\tSpeed: 950.23 samples/sec\taccuracy=0.987000\n",
      "INFO:root:Epoch[7] Batch [300]\tSpeed: 970.88 samples/sec\taccuracy=0.990000\n",
      "INFO:root:Epoch[7] Batch [400]\tSpeed: 979.05 samples/sec\taccuracy=0.987500\n",
      "INFO:root:Epoch[7] Batch [500]\tSpeed: 975.35 samples/sec\taccuracy=0.987800\n",
      "INFO:root:Epoch[7] Train-accuracy=0.989899\n",
      "INFO:root:Epoch[7] Time cost=61.836\n",
      "INFO:root:Epoch[7] Validation-accuracy=0.987400\n",
      "INFO:root:Epoch[8] Batch [100]\tSpeed: 968.42 samples/sec\taccuracy=0.990594\n",
      "INFO:root:Epoch[8] Batch [200]\tSpeed: 1003.81 samples/sec\taccuracy=0.988800\n",
      "INFO:root:Epoch[8] Batch [300]\tSpeed: 1001.14 samples/sec\taccuracy=0.991400\n",
      "INFO:root:Epoch[8] Batch [400]\tSpeed: 1005.83 samples/sec\taccuracy=0.988900\n",
      "INFO:root:Epoch[8] Batch [500]\tSpeed: 958.79 samples/sec\taccuracy=0.989500\n",
      "INFO:root:Epoch[8] Train-accuracy=0.992727\n",
      "INFO:root:Epoch[8] Time cost=61.031\n",
      "INFO:root:Epoch[8] Validation-accuracy=0.987500\n",
      "INFO:root:Epoch[9] Batch [100]\tSpeed: 975.06 samples/sec\taccuracy=0.991584\n",
      "INFO:root:Epoch[9] Batch [200]\tSpeed: 946.73 samples/sec\taccuracy=0.990700\n",
      "INFO:root:Epoch[9] Batch [300]\tSpeed: 938.19 samples/sec\taccuracy=0.992700\n",
      "INFO:root:Epoch[9] Batch [400]\tSpeed: 933.70 samples/sec\taccuracy=0.990800\n",
      "INFO:root:Epoch[9] Batch [500]\tSpeed: 909.99 samples/sec\taccuracy=0.990800\n",
      "INFO:root:Epoch[9] Train-accuracy=0.993838\n",
      "INFO:root:Epoch[9] Time cost=63.845\n",
      "INFO:root:Epoch[9] Validation-accuracy=0.988000\n"
     ]
    }
   ],
   "source": [
    "# create a trainable module on GPU 0\n",
    "lenet_model = mx.mod.Module(symbol=lenet,context=mx.cpu())\n",
    "# train with the same\n",
    "lenet_model.fit(train_iter,\n",
    "               eval_data=val_iter,\n",
    "               optimizer='sgd',\n",
    "               optimizer_params={'learning_rate':0.1},\n",
    "               eval_metric='acc',\n",
    "               batch_end_callback = mx.callback.Speedometer(batch_size,100),\n",
    "               num_epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EvalMetric: {'accuracy': 0.988}\n"
     ]
    }
   ],
   "source": [
    "# Prediction\n",
    "test_iter = mx.io.NDArrayIter(mnist['test_data'],None,batch_size)\n",
    "prob = lenet_model.predict(test_iter)\n",
    "test_iter = mx.io.NDArrayIter(mnist['test_data'],mnist['test_label'],batch_size)\n",
    "# predict accuracy for Lenet\n",
    "acc = mx.metric.Accuracy()\n",
    "lenet_model.score(test_iter,acc)\n",
    "print(acc)\n",
    "assert acc.get()[1] > 0,98"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
